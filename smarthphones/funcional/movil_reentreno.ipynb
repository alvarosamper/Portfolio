{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OBJETIVOS\n",
        "\n",
        "Nos contactaron para realizar un modelo que fuese capaz de identificar cuando un móvil aparecía por pantalla. Luego nos planteamos los siguientes objetivos.\n",
        "\n",
        "* Ser capaces de obtener múltiples imágenes de móviles en múltiples situaciones para poder generalizar de la mejor manera el modelo. (extraerframes.ipynb)\n",
        "\n",
        "* Realizar un etiquetado tipo Yolo, ya que nos centramos en realizar un ejercicio de transfer-learning partiendo de una red neuronal ya funcional.\n",
        "\n",
        "* Realizar el ejercicio de transfer-learning\n",
        "\n",
        "* Presentar alguno de los vídeos que demostrasen nuestro resultado.\n",
        "\n"
      ],
      "metadata": {
        "id": "DnC3S_G4Ag7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PLANTEAMIENTO Y DESARROLLO\n",
        "\n",
        "Voy a desarrollar de la forma más breve el desarrollo.\n",
        "\n",
        "Lo primero voy a comentar el modus operandi y como ha ido.\n",
        "\n",
        "En primer lugar, planteamos todo el desarrollo para ejecutarlo todo en formato \n",
        "Yolo, ya que al tener que re-entrenar esta red neuronal, debemos realizar las etiquetas\n",
        "y todo en su formato.\n",
        "\n",
        "Este paso es esencial pues necesitamos etiquetar imagen a imagen para poder realizar \n",
        "el entrenamiento de la red neuronal yolo v3.\n",
        "\n",
        "Una vez teníamos las imágenes descargadas y entrenadas. Debemos generar un fichero \n",
        ".data(creacion-data.ipynb), con la información de la ubicación del train.txt, test.txt, class.names y\n",
        "el backup donde guardaremos los pesos generados. Los elementos train.txt y test.txt\n",
        "deben tener la ubicación de cada una de las imágenes y cada una de las imágenes .jpg\n",
        "debe tener un fichero .txt con el mismo nombre y la misma ubicación con la explicación\n",
        "tipo yolo de donde se encuentra cada una de las clases a clasificar.\n",
        "\n",
        "Una vez tenemos todo esto generado, debemos hacer un entrenamiento de transfer-learning\n",
        "pero antes de realizar el entrenamiento de transfer-learning debemos hacer una \n",
        "modificación en la estructura de nuestra red neuronal, pues al estar entrenada a \n",
        "80 clases, debemos modificarla para ajustar a nuestros parámetros.\n",
        "\n",
        "Con esto hecho, debemos hacer ya el ejercicio de transfer-learning(transfer-learning.ipynb),\n",
        "ha sido un procesode unas 6 horas.\n",
        "\n",
        "Una vez hecho esto, realizamos una clasificación respecto a unos nuevos vídeos\n",
        "que hemos obtenido (movil-reentreno.ipynb)."
      ],
      "metadata": {
        "id": "25vJjKDYAdEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Código"
      ],
      "metadata": {
        "id": "AjRGT1ovAjGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isNIG1YUfT5g"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de la YOLO v3\n",
        "#Nombres de las clases\n",
        "with open(\"/content/drive/MyDrive/movil-final/imagenes/\"+ \"class.names\") as f:\n",
        "    labels = [line.strip() for line in f]\n",
        "\n",
        "\n",
        "network = cv2.dnn.readNetFromDarknet(\"/content/drive/MyDrive/movil-final/\"+ \"cell-yolov3.cfg\",\n",
        "                                     \"/content/drive/MyDrive/movil-final/backup/\" + \"cell-yolov3_best.weights\")\n",
        "\n",
        "layers_names_all = network.getLayerNames()\n",
        "\n",
        "layers_names_output = \\\n",
        "    [layers_names_all[i - 1] for i in network.getUnconnectedOutLayers()]\n",
        "\n",
        "probability_minimum = 0.3\n",
        "threshold = 0.3\n",
        "\n",
        "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n"
      ],
      "metadata": {
        "id": "MXwT2O46lEF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def movil_detection(nombre_video):\n",
        "  # CARGA DEL VIDEO Y LOOP DE LOS FRAMES\n",
        "  f=0\n",
        "  t=0\n",
        "  writer = None\n",
        "  h, w = None, None\n",
        "  video = cv2.VideoCapture(\"/content/drive/MyDrive/movil-final/videos/entrenamiento/\"+ nombre_video)\n",
        "\n",
        "  while True:\n",
        "    ret, frame=video.read()\n",
        "\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    if w is None or h is None:\n",
        "      h,w = frame.shape[:2]\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/ 255.0, (416,416), swapRB=True, crop=False)\n",
        "\n",
        "    #APLICACIÓN DEL NETWORK A LOS LOOPS\n",
        "    network.setInput(blob)\n",
        "    start=time.time()\n",
        "    output_from_network = network.forward(layers_names_output)\n",
        "    end=time.time()\n",
        "\n",
        "    f+=1\n",
        "    t+= end-start\n",
        "\n",
        "\n",
        "    bounding_boxes = []\n",
        "    confidences = []\n",
        "    class_numbers = []\n",
        "\n",
        "    for result in output_from_network:\n",
        "        for detected_objects in result:\n",
        "            scores = detected_objects[5:]\n",
        "            class_current = np.argmax(scores)\n",
        "            \n",
        "            confidence_current = scores[class_current]\n",
        "\n",
        "            if confidence_current > probability_minimum:\n",
        "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
        "\n",
        "                x_center, y_center, box_width, box_height = box_current\n",
        "                x_min = int(x_center - (box_width / 2))\n",
        "                y_min = int(y_center - (box_height / 2))\n",
        "\n",
        "                bounding_boxes.append([x_min, y_min,\n",
        "                                       int(box_width), int(box_height)])\n",
        "                confidences.append(float(confidence_current))\n",
        "                class_numbers.append(class_current)\n",
        "\n",
        "\n",
        "# FILTRADO DE LA MEJOR CAJA Y DIBUJADO DE ESTA \n",
        "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,\n",
        "                               probability_minimum, threshold)    \n",
        "    \n",
        "    if len(results) > 0:\n",
        "        \n",
        "        for i in results.flatten():\n",
        "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
        "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
        "\n",
        "            colour_box_current = colours[class_numbers[i]].tolist()\n",
        "\n",
        "            if   labels[int(class_numbers[i])]==\"cell phone\":\n",
        "              cv2.rectangle(frame, (x_min, y_min),\n",
        "                          (x_min + box_width, y_min + box_height),\n",
        "                          colour_box_current, 2)              \n",
        "              text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
        "                                                    confidences[i])\n",
        "\n",
        "              cv2.putText(frame, text_box_current, (x_min, y_min - 5),\n",
        "                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, colour_box_current, 2) \n",
        "\n",
        "    if writer is None:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "        writer = cv2.VideoWriter(\"/content/drive/MyDrive/movil-final/resultados/\" + nombre_video, fourcc, 30,\n",
        "                                 (frame.shape[1], frame.shape[0]), True)\n",
        "    writer.write(frame)   \n",
        "  print()\n",
        "  print(\"Nombre_archivo:\", nombre_video)\n",
        "  print('Numero de imágenes', f)\n",
        "  print('Tiempo en Minutos: {:.5f}'.format(t/60))\n",
        "  print('FPS:', round((f / t), 1))\n"
      ],
      "metadata": {
        "id": "XJ9Xoy0Gj8C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_videos4=[\"movil1.mp4\",\"movil2.mp4\",\"movil3.mp4\",\"movil4.mp4\",\"movil5.mp4\",\"movil6.mp4\"]\n",
        "for x in lista_videos4:\n",
        "  movil_detection(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwlLtZv-ejj6",
        "outputId": "b4562afb-0339-402b-9ea5-a45e7dbe726e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nombre_archivo: movil1.mp4\n",
            "Numero de imágenes 573\n",
            "Tiempo en Minutos: 11.17839\n",
            "FPS: 0.9\n",
            "\n",
            "Nombre_archivo: movil2.mp4\n",
            "Numero de imágenes 826\n",
            "Tiempo en Minutos: 16.11816\n",
            "FPS: 0.9\n",
            "\n",
            "Nombre_archivo: movil3.mp4\n",
            "Numero de imágenes 672\n",
            "Tiempo en Minutos: 13.11464\n",
            "FPS: 0.9\n",
            "\n",
            "Nombre_archivo: movil4.mp4\n",
            "Numero de imágenes 269\n",
            "Tiempo en Minutos: 5.23140\n",
            "FPS: 0.9\n",
            "\n",
            "Nombre_archivo: movil5.mp4\n",
            "Numero de imágenes 577\n",
            "Tiempo en Minutos: 11.27834\n",
            "FPS: 0.9\n",
            "\n",
            "Nombre_archivo: movil6.mp4\n",
            "Numero de imágenes 920\n",
            "Tiempo en Minutos: 17.92388\n",
            "FPS: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejNY3M8ciw6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}